# src/matchers.py
from typing import List, Tuple
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer, util
import numpy as np
import nltk
nltk.download('punkt', quiet=True)
import re
try:
    from nltk.tokenize import sent_tokenize
except:
    def sent_tokenize(text):
        text = text.strip()
        if not text:
            return []
        parts = re.split(r'(?<=[.!?])\s+', text)
        return [p.strip() for p in parts if p.strip()]


class TfidfMatcher:
    def __init__(self, ngram_range=(1,2), max_features=10000):
        self.ngram_range = ngram_range
        self.vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features, stop_words='english')

    def fit(self, documents: List[str]):
        self.vectorizer.fit(documents)

    def score_document(self, jd_text: str, doc_text: str) -> Tuple[float, List[Tuple[str,float]]]:
        tfidf = self.vectorizer
        vecs = tfidf.transform([jd_text, doc_text])
        sim = float(cosine_similarity(vecs[0], vecs[1])[0,0])
        jd_vec = vecs[0].toarray().ravel()
        doc_vec = vecs[1].toarray().ravel()
        term_scores = {}
        feature_names = tfidf.get_feature_names_out()
        for idx, term in enumerate(feature_names):
            score = min(jd_vec[idx], doc_vec[idx])
            if score > 0:
                term_scores[term] = float(score)
        sorted_terms = sorted(term_scores.items(), key=lambda x: -x[1])[:20]
        return sim, sorted_terms

class SbertMatcher:
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model_name = model_name
        self.model = SentenceTransformer(model_name)

    def fit(self, documents: List[str]):
        self.documents = documents

    def _embed_sentences(self, text: str):
        sents = sent_tokenize(text)
        if not sents:
            sents = [text]
        embeddings = self.model.encode(sents, convert_to_tensor=True)
        return sents, embeddings

    def score_document(self, jd_text: str, doc_text: str, top_k_sentences=5):
        jd_emb = self.model.encode(jd_text, convert_to_tensor=True)
        sents, sent_embs = self._embed_sentences(doc_text)
        sims = util.cos_sim(jd_emb, sent_embs)[0].cpu().numpy()
        doc_emb = sent_embs.mean(axis=0)
        doc_sim = util.cos_sim(jd_emb, doc_emb)[0].item()
        top_idx = list(np.argsort(-sims)[:top_k_sentences])
        top_sents = [sents[i] for i in top_idx]
        top_scores = [float(sims[i]) for i in top_idx]
        top = list(zip(top_sents, top_scores))
        return float(doc_sim), top

def combined_ranking(tfidf_score: float, sbert_score: float, tfidf_weight: float = 0.4, sbert_weight: float = 0.6) -> float:
    return float(tfidf_weight * tfidf_score + sbert_weight * sbert_score)
